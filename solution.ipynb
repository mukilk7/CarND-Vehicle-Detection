{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Define functions to compute input features from dataset car/non-car images.\n",
    "    - Color space change, Spatial binning, Color histogram, HOG with subsampling\n",
    "* Combine (concatenate) input features, normalize/scale (using sklearn StandardScaler) them.\n",
    "* Using a balanced dataset and shuffled train/test splits, train a single or ensemble of classifiers to detect cars.\n",
    "    - Linear SVM, Decision trees, Deep neural networks\n",
    "* Implement a generic sliding window technique that feeds patches from a given image to classifier for classification.\n",
    "    - Use multiple window sizes\n",
    "    - Come up with efficient scan strategy (e.g. only bottom half of image)\n",
    "* Implement heatmap thresholding to combine multiple detections and remove false positives\n",
    "* Use information from multiple frames to remove spurious false positives that appear in one or small number of frames.\n",
    "    - Calculate motion trajectory if required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Helper Functions\n",
    "\n",
    "def readImage(imfile):\n",
    "    img = cv2.imread(imfile)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def plotImageFiles(filenames):\n",
    "    for f in filenames:\n",
    "        fig = plt.figure()\n",
    "        #fig.set_size_inches(3,6)\n",
    "        img = readImage(f)\n",
    "        plt.title(f)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        \n",
    "def plotImage(img, title=None, cmap=None):\n",
    "    fig = plt.figure()\n",
    "    #fig.set_size_inches(4,8)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    #plt.axis('off')\n",
    "    if cmap is None:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    \n",
    "def plotMultipleImages(images, labels=None, ptitle=None, cmap=None):\n",
    "    \"\"\" This function will plot the images specified in a\n",
    "    single plot.\n",
    "    \"\"\"\n",
    "    numImages = len(images)\n",
    "    ii = 1\n",
    "    for img in images:\n",
    "        fig = plt.figure()\n",
    "        if labels is not None:\n",
    "            plt.title(labels[ii-1], fontsize=\"xx-small\")\n",
    "        #plt.axis('off')\n",
    "        if cmap is not None:\n",
    "            plt.imshow(img.squeeze(), cmap=cmap)\n",
    "        else:\n",
    "            plt.imshow(img.squeeze())\n",
    "        ii += 1\n",
    "\n",
    "def plotRectangles(img, bboxes, color=(0, 0, 255), thick=6, title=None):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    plt.figure()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.imshow(imcopy)\n",
    "    \n",
    "print(\"*** Helper Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertImageColorSpace(img, color_space):\n",
    "    \"\"\" Convenient wrapper over opencv cvtColor.\n",
    "    \"\"\"\n",
    "    # Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else:\n",
    "        feature_image = np.copy(img)\n",
    "    return feature_image\n",
    "        \n",
    "\n",
    "def getBinSpatialFeatures(img, size=(32, 32)):\n",
    "    \"\"\" Computes spatially binned color features\n",
    "    \"\"\"\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    return features\n",
    "\n",
    "def getColorHistogramFeatures(img, nbins=32, bins_range=(0, 256)):\n",
    "    \"\"\" Computes color histogram of features for each image channel\n",
    "    and combines them into a single feature vector.\n",
    "    \"\"\"\n",
    "    channelhists = []\n",
    "    for i in range(0, img.shape[2]):\n",
    "        channelhist = np.histogram(img[:,:,i], bins=nbins, range=bins_range)\n",
    "        channelhists.append(channelhist[0])\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate(channelhists)\n",
    "    return hist_features\n",
    "\n",
    "def getHOGFeatures(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    \"\"\" Computes and returns HOG features and visualization (optional).\n",
    "    NOTE: Hog automatically does (100/cell_per_block)% overlap between\n",
    "    blocks.\n",
    "    \"\"\"\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "def extractImageFeatures(img, params):    \n",
    "    \"\"\" Returns a combined image feature vector for given single image.\n",
    "    \"\"\"\n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    feature_image = convertImageColorSpace(img, params['color_space'])\n",
    "    #3) Compute spatial features if flag is set\n",
    "    if params['spatial_feat'] == True:\n",
    "        spatial_features = getBinSpatialFeatures(feature_image, size=params['spatial_size'])\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if params['hist_feat'] == True:\n",
    "        hist_features = getColorHistogramFeatures(feature_image, nbins=params['hist_bins'])\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if params['hog_feat'] == True:\n",
    "        if params['hog_channel'] == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(getHOGFeatures(feature_image[:,:,channel], \n",
    "                                    params['orient'], params['pix_per_cell'],\n",
    "                                    params['cell_per_block'], vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = getHOGFeatures(feature_image[:,:,params['hog_channel']], params['orient'], \n",
    "                        params['pix_per_cell'], params['cell_per_block'], vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "        print(hog_features[0].shape)\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "def batchExtractImageFeatures(imgfiles, params):\n",
    "    \"\"\" Returns list of combined image feature vectors for the given batch\n",
    "    of images.\n",
    "    \"\"\"\n",
    "    batch_features = []\n",
    "    for imfile in imgfiles:\n",
    "        img = readImage(imfile)\n",
    "        features = extractImageFeatures(img, params)\n",
    "        batch_features.append(features)\n",
    "    return batch_features\n",
    "\n",
    "def plotSampleHogImages():\n",
    "    carfiles = glob.glob('data/vehicles/**/*.png', recursive=True)\n",
    "    noncarfiles = glob.glob('data/non-vehicles/**/*.png', recursive=True)\n",
    "    samples = min(len(carfiles), len(noncarfiles))\n",
    "    ind = random.randint(0, samples-1)\n",
    "    carimg = readImage(carfiles[ind])\n",
    "    noncarimg = readImage(noncarfiles[ind])\n",
    "    gscarimg = cv2.cvtColor(carimg, cv2.COLOR_RGB2GRAY)\n",
    "    gsnoncarimg = cv2.cvtColor(noncarimg, cv2.COLOR_RGB2GRAY)\n",
    "    _, carhogvis = getHOGFeatures(gscarimg, orient=9, pix_per_cell=4, cell_per_block=2, vis=True, feature_vec=True)\n",
    "    _, noncarhogvis = getHOGFeatures(gsnoncarimg, orient=9, pix_per_cell=4, cell_per_block=2, vis=True, feature_vec=True)\n",
    "    plotMultipleImages([carimg, carhogvis], cmap=\"gray\")\n",
    "\n",
    "#plotSampleHogImages()\n",
    "    \n",
    "print(\"*** Input Features Computation Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getClassifierParams():\n",
    "    params = dict()\n",
    "    params['color_space'] = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "    params['orient'] = 9  # HOG orientations\n",
    "    params['pix_per_cell'] = 8 # HOG pixels per cell\n",
    "    params['cell_per_block'] = 2 # HOG cells per block\n",
    "    params['hog_channel'] = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "    params['spatial_size'] = (16, 16) # Spatial binning dimensions\n",
    "    params['hist_bins'] = 16    # Number of histogram bins\n",
    "    params['spatial_feat'] = False # Spatial features on or off\n",
    "    params['hist_feat'] = True # Histogram features on or off\n",
    "    params['hog_feat'] = True # HOG features on or off\n",
    "    return params\n",
    "    \n",
    "\n",
    "def getTrainedClassifier(datafile = \"./classifier/svc.pickle\", forcetrain=False):\n",
    "    \"\"\" Loads a pre-trained classifier if available or trains a new one.\n",
    "    It takes care of loading up the dataset images, extracting the image\n",
    "    features, normalizing them and training the classifier and saving it\n",
    "    if its the first time or forceTrain is True.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(datafile) and not forcetrain:\n",
    "        print(\"--> Returning saved classifier\")\n",
    "        with open(datafile, \"rb\") as f:\n",
    "            pickledata = pickle.load(f)\n",
    "            clf = pickledata[\"classifier\"]\n",
    "            return clf\n",
    "    carfiles = glob.glob('data/vehicles/**/*.png', recursive=True)\n",
    "    noncarfiles = glob.glob('data/non-vehicles/**/*.png', recursive=True)\n",
    "    numsamples = min(len(carfiles), len(noncarfiles))\n",
    "    params = getClassifierParams()\n",
    "    print(\"--> Extracting features. Numsamples = \", numsamples)\n",
    "    carfeatures = batchExtractFeatures(carfiles[0:numsamples], params)\n",
    "    noncarfeatures = batchExtractFeatures(noncarfiles[0:numsamples], params)\n",
    "    X = np.vstack((carfeatures, noncarfeatures)).astype(np.float64)                        \n",
    "    print(\"--> Scaling features\")\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(carfeatures)), np.zeros(len(noncarfeatures))))\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "    # Use a linear SVC \n",
    "    svc = LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    print(\"--> Starting to Train Classifier\")\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(\"--> \", round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    print('--> Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    print(\"--> Saving Classifier\")    \n",
    "    t=time.time()\n",
    "    with open(datafile, \"wb\") as f:\n",
    "        pickle.dump( { 'classifier': svc,}, f, pickle.HIGHEST_PROTOCOL )\n",
    "    return svc\n",
    "\n",
    "svc = getTrainedClassifier()\n",
    "\n",
    "print(\"*** Classifier Training Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotSlidingWindows(img, scale, ystart=None, ystop=None):\n",
    "    \"\"\" Debug function to plot sliding windows over image.\n",
    "    \"\"\"\n",
    "    if ystart is None or ystop is None:\n",
    "        #Select bottom half and snip out the hood\n",
    "        ystart, ystop = img.shape[0]//2, int(img.shape[0] * 0.9)\n",
    "    wimg = img[ystart:ystop,:,:]\n",
    "    wimshape = wimg.shape\n",
    "    if scale != 1:\n",
    "        wimg = cv2.resize(wimg, (int(wimshape[1]/scale), int(wimshape[0]/scale)))\n",
    "    winszxpix = winszypix = 64\n",
    "    xsteps = wimg.shape[1] // winszxpix\n",
    "    ysteps = wimg.shape[0] // winszypix\n",
    "    bboxes = []\n",
    "    for y in range(0, ysteps):\n",
    "        for x in range(0, xsteps):\n",
    "            tl = (x * winszxpix, y * winszypix)\n",
    "            br = (x * winszxpix + winszxpix, y * winszypix + winszypix)\n",
    "            bboxes.append((tl, br))\n",
    "    plotRectangles(wimg, bboxes, title=\"Scale = \" + str(scale))\n",
    "\n",
    "def slidingWindowCarDetect(clf, img, scale, ystart=None, ystop=None):\n",
    "    \"\"\" This function slides a window of specified size over given image\n",
    "    in x and y directions and computes features for each window and runs\n",
    "    it through a classifier to determine if we've identified a car in the\n",
    "    window.\n",
    "    The window size is fixed but we can change the image size using the scale\n",
    "    parameter. In essense, we fix the window size and change the canvas size\n",
    "    to get multi-scale windows in which to search for cars.\n",
    "    \"\"\"\n",
    "    if ystart is None or ystop is None:\n",
    "        #Select bottom half and snip out the hood\n",
    "        ystart, ystop = img.shape[0]//2, int(img.shape[0] * 0.9)\n",
    "    #Get the same parameters used for training the classifier and reuse for sanity\n",
    "    params = getClassifierParams()\n",
    "    wimg = convertImageColorSpace(img[ystart:ystop,:,:], params['color_space'])\n",
    "    #Normalize\n",
    "    wimg = wimg.astype(np.float32) / 255\n",
    "    #The original training dataset had 64x64 images.\n",
    "    #So we need to size each window to the same dimensions.\n",
    "    windowszx = windowszy = 64\n",
    "    wimshape = wimg.shape\n",
    "    if scale != 1:\n",
    "        wimg = cv2.resize(wimg, (int(wimshape[1]/scale), int(wimshape[0]/scale)))\n",
    "    #Get HOG features for whole image on all channels\n",
    "    #NOTE: Hog features for each channel will be of shape:\n",
    "    #nblocksy, nblocksx, cell_per_block, cell_per_block, orient)\n",
    "    hog_features = []\n",
    "    if params['hog_channel'] == 'ALL':\n",
    "        for channel in range(wimg.shape[2]):\n",
    "            hf = getHOGFeatures(wimg[:,:,channel], params['orient'], params['pix_per_cell'],\n",
    "                                params['cell_per_block'], vis=False, feature_vec=False)\n",
    "            hog_features.append(hf)\n",
    "    else:\n",
    "        hf = getHOGFeatures(wimg[:,:,params['hog_channel']], params['orient'], params['pix_per_cell'],\n",
    "                            params['cell_per_block'], vis=False, feature_vec=False)\n",
    "        hog_features.append(hf)\n",
    "    print(\"single channel hog shape = \", hog_features[0].shape)\n",
    "\n",
    "    \n",
    "print(\"*** Sliding Window Technique Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Combining Overlaps and False Positives Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"*** Overlap Combining and False Positives Removal Functions Defined ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Overall Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    clf = getTrainedClassifier()\n",
    "    slidingWindowCarDetect(clf, img, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testPipelineOnTestImages():\n",
    "    tfiles = glob.glob('test_images/test*.jpg')\n",
    "    for tfile in tfiles:\n",
    "        timg = readImage(tfile)\n",
    "        #plt.figure(figsize=(10, 12))\n",
    "        #plt.imshow(timg)\n",
    "        pipeline(timg)\n",
    "        break\n",
    "\n",
    "testPipelineOnTestImages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Vehicle Detection on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "#TODO: Basic pre-processing\n",
    "\n",
    "def process_image(image):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prevllfit = None\n",
    "prevrlfit = None\n",
    "outvideofile = 'project_video_output.mp4'\n",
    "pvideo = VideoFileClip(\"project_video.mp4\")\n",
    "ovideo = pvideo.fl_image(process_image)\n",
    "%time ovideo.write_videofile(outvideofile, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(outvideofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
